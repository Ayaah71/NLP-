ðŸ§  Exploring NLP Through OCR and Web Scraping: Two Hands-On Projects
Natural Language Processing (NLP) is a rapidly evolving field that blends linguistics, computer science, and AI to enable machines to understand and process human language. As part of our coursework at Alamein International University, we engaged in two hands-on NLP projects that tackled different challenges: extracting structured text from images using OCR, and exploring tokenization techniques through recursive web scraping.

ðŸ“˜ Assignment 1: Text Extraction and Regex Processing with Tesseract OCR
This assignment focused on extracting meaningful data from image-based text using Optical Character Recognition (OCR) powered by Tesseract. We processed an image containing various pieces of informationâ€”names, emails, phone numbers, and moreâ€”then applied custom regular expressions to identify and extract specific elements.

Key Components:

OCR: Used Tesseract to convert image content into text.

Regex: Designed and applied patterns to extract emails, dates, phone numbers, URLs, time stamps, codes, and monetary amounts.

Output: A structured Python dictionary organizing the extracted data.

This task emphasized the importance of preprocessing and robust pattern design when dealing with unstructured or image-based data sources.

ðŸ“™ Assignment 2: Recursive Web Scraping and Tokenization Analysis
In this project, we explored a full NLP pipeline starting from web data collection to linguistic analysis using various tokenization methods. We implemented recursive scraping to collect a large text corpus from websites, then applied tokenization strategies including Word-level, WordPiece, and Byte Pair Encoding (BPE).

Project Highlights:

Web Scraping: Developed a recursive scraper to extract textual content from web pages.

Preprocessing: Cleaned and prepared the text for NLP analysis.

Tokenization: Compared traditional and subword-based techniques to evaluate vocabulary efficiency and semantic granularity.

Visualization: Created word maps to visually represent token frequency and relevance.

The comparison revealed how subword models like BPE and WordPiece handle out-of-vocabulary words and offer better coverage for complex linguistic structures.

ðŸ‘¥ Team Reflection
Both assignments were completed collaboratively by:

Aya Mamdouh Ahmed Elhabashy 

Rodina Mohamed Saeed Hassan 

Each member contributed equally by splitting responsibilities across implementation, debugging, and analysis. The challenges facedâ€”such as Tesseract configuration issues or BPE tokenizer tuningâ€”were overcome through teamwork and iterative problem-solving.

These projects provided invaluable insight into real-world applications of NLP. By combining theory with coding, we deepened our understanding of how machines interpret, extract, and analyze human language.
